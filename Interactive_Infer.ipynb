{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Inference config:\n",
      "{'batch_size_per_gpu': 64,\n",
      " 'data_layer': <class 'open_seq2seq.data.text2text.text2text.ParallelTextDataLayer'>,\n",
      " 'data_layer_params': {'delimiter': ' ',\n",
      "                       'max_length': 64,\n",
      "                       'pad_vocab_to_eight': True,\n",
      "                       'repeat': False,\n",
      "                       'shuffle': False,\n",
      "                       'source_file': '../OpenSeq2Seq/wmt16_en_dt/newstest2014.tok.bpe.32000.de',\n",
      "                       'src_vocab_file': '../OpenSeq2Seq/wmt16_en_dt/vocab.bpe.32000',\n",
      "                       'target_file': '../OpenSeq2Seq/wmt16_en_dt/newstest2014.tok.bpe.32000.de',\n",
      "                       'tgt_vocab_file': '../OpenSeq2Seq/wmt16_en_dt/vocab.bpe.32000'},\n",
      " 'decoder': <class 'open_seq2seq.decoders.convs2s_decoder.ConvS2SDecoder'>,\n",
      " 'decoder_params': {'END_SYMBOL': 1,\n",
      "                    'EOS_ID': 1,\n",
      "                    'GO_SYMBOL': 2,\n",
      "                    'PAD_SYMBOL': 0,\n",
      "                    'alpha': 0.6,\n",
      "                    'beam_size': 5,\n",
      "                    'conv_activation': <function gated_linear_units at 0x7f1f9350dd08>,\n",
      "                    'conv_nchannels_kwidth': [(512, 3),\n",
      "                                              (512, 3),\n",
      "                                              (512, 3),\n",
      "                                              (512, 3),\n",
      "                                              (512, 3),\n",
      "                                              (512, 3),\n",
      "                                              (512, 3),\n",
      "                                              (512, 3),\n",
      "                                              (512, 3),\n",
      "                                              (1024, 3),\n",
      "                                              (1024, 3),\n",
      "                                              (1024, 3),\n",
      "                                              (1024, 3),\n",
      "                                              (2048, 1),\n",
      "                                              (2048, 1)],\n",
      "                    'decoder_layers': 15,\n",
      "                    'embedding_dropout_keep_prob': 0.8,\n",
      "                    'extra_decode_length': 56,\n",
      "                    'hidden_dropout_keep_prob': 0.8,\n",
      "                    'max_input_length': 64,\n",
      "                    'normalization_type': 'weight_norm',\n",
      "                    'out_dropout_keep_prob': 0.8,\n",
      "                    'out_emb_size': 512,\n",
      "                    'pad_embeddings_2_eight': True,\n",
      "                    'pos_embed': True,\n",
      "                    'shared_embed': True,\n",
      "                    'tgt_emb_size': 512},\n",
      " 'dtype': 'mixed',\n",
      " 'encoder': <class 'open_seq2seq.encoders.convs2s_encoder.ConvS2SEncoder'>,\n",
      " 'encoder_params': {'PAD_SYMBOL': 0,\n",
      "                    'att_layer_num': 15,\n",
      "                    'conv_activation': <function gated_linear_units at 0x7f1f9350dd08>,\n",
      "                    'conv_nchannels_kwidth': [(512, 3),\n",
      "                                              (512, 3),\n",
      "                                              (512, 3),\n",
      "                                              (512, 3),\n",
      "                                              (512, 3),\n",
      "                                              (512, 3),\n",
      "                                              (512, 3),\n",
      "                                              (512, 3),\n",
      "                                              (512, 3),\n",
      "                                              (1024, 3),\n",
      "                                              (1024, 3),\n",
      "                                              (1024, 3),\n",
      "                                              (1024, 3),\n",
      "                                              (2048, 1),\n",
      "                                              (2048, 1)],\n",
      "                    'embedding_dropout_keep_prob': 0.8,\n",
      "                    'encoder_layers': 15,\n",
      "                    'hidden_dropout_keep_prob': 0.8,\n",
      "                    'max_input_length': 64,\n",
      "                    'normalization_type': 'weight_norm',\n",
      "                    'pad_embeddings_2_eight': True,\n",
      "                    'src_emb_size': 512},\n",
      " 'eval_steps': 12304,\n",
      " 'logdir': '/logdata/logs/87641/testdetoen/logs/',\n",
      " 'loss': <class 'open_seq2seq.losses.sequence_loss.BasicSequenceLoss'>,\n",
      " 'loss_params': {'average_across_timestep': True,\n",
      "                 'do_mask': True,\n",
      "                 'offset_target_by_one': True},\n",
      " 'loss_scaling': 'Backoff',\n",
      " 'lr_policy': <function transformer_policy at 0x7f1f93482730>,\n",
      " 'lr_policy_params': {'d_model': 512,\n",
      "                      'learning_rate': 9,\n",
      "                      'max_lr': 0.001,\n",
      "                      'warmup_steps': 4000},\n",
      " 'max_grad_norm': 0.1,\n",
      " 'max_steps': 1230468,\n",
      " 'num_gpus': 1,\n",
      " 'optimizer': 'Adam',\n",
      " 'optimizer_params': {},\n",
      " 'print_loss_steps': 1230,\n",
      " 'print_samples_steps': None,\n",
      " 'save_checkpoint_steps': 246093,\n",
      " 'save_summaries_steps': 1230,\n",
      " 'summaries': ['learning_rate',\n",
      "               'variables',\n",
      "               'gradients',\n",
      "               'larc_summaries',\n",
      "               'variable_norm',\n",
      "               'gradient_norm',\n",
      "               'global_gradient_norm',\n",
      "               'loss_scale'],\n",
      " 'use_horovod': False}\n",
      "*** Loading model from /logdata/logs/87641/testdetoen/logs/model.ckpt-153808\n",
      "*** Building graph on GPU:0\n",
      "*** Inference Mode. Loss part of graph isn't built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vnoroozi/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py:1714: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /logdata/logs/87641/testdetoen/logs/model.ckpt-153808\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import run\n",
    "import IPython\n",
    "from open_seq2seq.utils.utils import get_results_for_epoch\n",
    "from open_seq2seq.models.text2speech import save_audio\n",
    "args = [\"--config_file=/logdata/logs/87641/testdetoen/config_2018-07-25_21-48-28.py\",\n",
    "        \"--mode=interactive_infer\",\n",
    "        \"--logdir=/logdata/logs/87641/testdetoen/logs/\",\n",
    "        \"--infer_output_file=unused\",\n",
    "        \"--batch_size_per_gpu=1\",\n",
    "        \"--num_gpus=1\",\n",
    "]\n",
    "output_file = \"unused\"\n",
    "\n",
    "model, checkpoint, graph = run.main(args)\n",
    "sess_config = tf.ConfigProto(allow_soft_placement=True)\n",
    "sess_config.gpu_options.allow_growth = True\n",
    "sess = tf.InteractiveSession(graph=graph, config=sess_config)\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "import codecs\n",
    "import os,sys,inspect\n",
    "\n",
    "from subword_nmt.learn_bpe import learn_bpe\n",
    "from subword_nmt.apply_bpe import BPE\n",
    "\n",
    "bpe_vocab_file = \"bpe.32000\"\n",
    "with codecs.open(bpe_vocab_file, encoding='utf-8') as bpefile:\n",
    "    bpe = BPE(bpefile)\n",
    "\n",
    "line=\"verlängert , es kommt also jeder sicher über die Fahrbahn &quot; , erklärte Arnold .\"\n",
    "input=[bpe.process_line(line)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Processed 1/1 batches\n",
      "*** Processed 1/1 batches\n",
      "*** Not enough steps for benchmarking\n"
     ]
    }
   ],
   "source": [
    "#input = [\"verlängert , es kommt also jeder sicher über die Fahrbahn &quot; , erklärte Arnold .\"]\n",
    "results = get_results_for_epoch(model, sess, compute_loss=False, mode=\"interactive_infer\", verbose=True, input=input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This means that everyone is safe on the road , &quot; explained Arnold .\n"
     ]
    }
   ],
   "source": [
    "# Model specific post_processing\n",
    "import re\n",
    "out=results[0][1][0]\n",
    "out = re.sub(\"@@ \", \"\", out)\n",
    "print(out)\n",
    "# prediction = results[0][1][1][0]\n",
    "# audio_length = results[0][1][4][0]\n",
    "# prediction = prediction[:audio_length-1,:]\n",
    "# prediction = model.get_data_layer().get_magnitude_spec(prediction)\n",
    "# wav = save_audio(prediction, \"unused\", \"unused\", save_format=\"np.array\")\n",
    "# IPython.display.Audio(wav, rate=22050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
